\documentclass[12pt]{article}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\lstset{
	basicstyle=\small\ttfamily,
	columns=flexible
	breaklines=true
}
\title{\textbf{Prototyping a Simplified Machine Code File Format For Libraries and Executables}}
\author{\textbf{Author}\\David Gonzalez Martin\\\\\textbf{Thesis advisor}\\Belen Bermejo Gonzalez\\\\\textbf{Coordinating professor}\\Josep Jorba Esteve\\\\\textbf{University}\\Universitat Oberta de Catalunya}
\date{June 2024}

\begin{document}
	\maketitle{}
	\newpage
	\tableofcontents
	\newpage
	\section{Introduction}
	\paragraph{}Nowadays modern software development has dramatically increased in complexity and both the user and the developer ends experiment problems around it. This work is aimed towards reducing the complexity when directly producing native executable and library binaries.
	\paragraph{}The development of this thesis is fully open-source, so the source code for both this memory and the linker/loader program can be consulted\cite{self}.
	\subsection{Context and Rationale}
	\paragraph{}In modern days there is significant complexity in software, both for the developer and the user. The paradigm for home computing shifted towards web applications as a way to fill the gap that traditional software failed to occupy: cross-platform software. The trend in the developer sector was to forget about memory management and garbage collection started dominating most of common software, especially in the business field. Types were an obstacle to developers, who demanded more and more flexibility, and dynamic typing appeared, leading to the emergence of interpreters and just-in-time compilers.
	\paragraph{}Nevertheless, this cannot only be sensed in the web and business software development world. Systems programming is infected with this fashion as well.
	\paragraph{} The enormous complexity inherited from the times when UNIX was born has generated an overwhelming environment for both users and developers. Code is duplicated or triplicated, leaving the developer with the obligation to deal with more software than necessary and users see how binary files tend to multiply in their disk with no direct corelation with any new feature or improvement whatsoever.
	\paragraph{}Modern compilers and operating systems and complex system software in general are about millions of lines of code, when Linux started out very simple, with just about 20 thousand lines of code. Now the Linux repository is over 20 millions lines of code. Veteran developers like Casey Muratori have criticized the complexity derived of the exponentially increasing lines of code of critical projects\cite{thirty-million}.
	\paragraph{}On Linux there are several problems when targetting graphics applications because you cannot link statically since proprietary drivers ship with a specific version of glibc. Provided that your system might not provide certain versions of glibc, an executable might not run if the version of glibc that was linked with is not located. Linux provides a stable system call interface but this benefit is lost when linking with glibc, which is common practice, translating from Microsoft land the so-called term "DLL hell".
	\subsection{Goals}
	\paragraph{}The general goal of the project is to untangle and reduce the complexity that modern operating systems have between redundant binary components and introduce simple solutions to some of latent problems that the unnecessary separation has been adding.	
	\paragraph{}Some of the problems that I have observed and that I would like to tackle in my work are:
	\begin{itemize}
		\item Suppress the distinction between dynamic and static libraries with respect to the file format. One file format should comprehend both and both could live in the same binary, giving the chance to the linker to pick the desired linking mode.
		\item Eliminate the distinction between command line interface (CLI) programs and libraries. Most Linux utilities, like \verb|grep| or \verb|ls|, are standalone programs which link libraries to fulfill their purpose. Instead, the proposal is to have a single binary file which can act both as a library and as an executable.
		\item Allow the user of the format to have different programs hosted inside a single executable. This would allow good capabilities of customization and, what is more important, the following case:
		\item Loader custom logic, allowing the user, among other abilities, to produce an in-memory code section fit for the used CPU architecture, features and instructions.
	\end{itemize}
	\paragraph{}There are a few ideas which are incredibly temptative to work on, but due to the scope of the project must be unfortunately left aside. Some of the most relevant ones are:
	\begin{itemize}
		\item Implementing a feature system which is both extensible and efficient.
		\item Implementing linking based on integer identification numbers instead of strings or names.
		\item Taking into account security when designing the format. It is a crucial aspect both in modern software and hardware, but again for time reasons must be left aside for the moment.
		\item A good algorithm or implementation to merge sections. Instead, an idea of units or packs will be used.
	\end{itemize}

	\subsection{Impact on Sustainability and Diversity and Social-Ethical Influence}
    \paragraph{} Developing a new executable and library format will yield enormous gains in disk space, which will translate in files being in the operating system filesystem cache more frequently and thus leading to faster program loading and less CPU cache pollution. All of this will translate to less energy consumed by computers, but not only because of the previous factors mentioned. Correct CPU instruction selection is crucial to save both energy and time, as professor Daniel Lemire states \cite{lemire-energy}. 
	\subsection{Used Method and Approach}
	\paragraph{}This work will only be addressing the x86\_64 architecture along with the GNU/Linux operating system, for a matter of simplicity and time limitation. For the same reason, no existing libraries will be used.
    
    \paragraph{}The skeleton of the project will be a program which works both as a linker and as a loader, it being able to generate binaries, load them from disk and resolve relocations, as well as setting them up for execution.
    
    \paragraph{}At the same time, current executable and library formats will be examined to look for good concepts to integrate into this more modern format and bad practices to be avoided.
    
    \paragraph{}Moreover, relocation types will be examined with a critical approach. Part of the complexity had in binary formats which contain native code is the wide range of unnecessary features. The investment in such features is widespread and unfortunately such practice is normalized.
    
    \paragraph{} With respect to the production of the relevant machine code, manual encoding will be used despite the existence of a few production-ready assemblers for x86\_64. 
    
    \paragraph{} The reasoning behind of all these decisions will be described in detail in the next sections.

%	\subsection{Planning}
%	
%	\subsection{Result Preview}
%	TODO

	\subsection{Thesis Overview}
	The main proposal of this work is to develop a prototype of a machine code format for both libraries and executable, aiming to simplify the current state of affairs. This targets the suppression of duplicities such as executables versus libraries, dynamic versus static linking, different relocation types and merging altogether, object format versus executable/library format, etc.
	
	\section{Resources and Approach}
	
	\paragraph{}Since the target of this work is the x86\_64 architecture and the GNU/Linux operating system, the research on the state of affairs is going to be as well on the formats used by this platform, that is, the ELF specification and the System V ABI (for x86\_64).

	\subsection{A brief exploration of ELF}
	
	\paragraph{}ELF stands for Executable and Linkable Format and is a binary file format used by Linux and other UNIX-like operating systems, such as the BSD family and Solaris, among others.
	\paragraph{}In what follows, different particularities of ELF which are relevant to this research will be described.
	
	\subsubsection{Types of ELF files}
	
	\paragraph{}According to the ELF specification\cite{elf-spec}, there are three main kinds of ELF files, also called by the spec as \textit{object} files:
	\begin{itemize}
		\item A relocatable file, which is supposed to be linked to other objects afterwards.
		\item An executable file, which can be used for direct execution.
		\item A shared object file, which may be used both to produce a bigger object file by linking to other objects or, primarily, can be linked at runtime with an executable file by the dynamic linker, and these are indexed by the program headers.
	\end{itemize}
	\paragraph{}However, by examining the \verb|e_type| field of the ELF header data structure, aside from the main types (\verb|ET_REL| for relocatable files, \verb|ET_EXEC| for executable files and \verb|ET_DYN| for shared object files), there is another type of file supported under the \verb|ET_CORE| tag, which refers mainly to core dumps.
	
	\subsubsection{Sections and program headers duality}
	
	\paragraph{}ELF files classify data into groups by means of both sections and segments. \paragraph{}Data in sections refer to all information valuable to the linking process and they are indexed by the section headers.
	\paragraph{}On the other hand, the data contained in the program segments contain all the information needed for constructing the process or executable image, that is, the bytes that need to be in memory in order for the program to work properly.
	\paragraph{}ELF being a general-purpose format, it has to support a wide variety of use cases in both the section and program headers.
	\paragraph{}Therefore, section headers have to support cases with no apparent utility, such as null sections. Others types supported are very specific to certain cases, which are included in this bloated scheme of linking the equally swolen web of code. The paradigmatic case of this is again the GNU libc. To exemplify the amount of sections, an optimized executable (non-stripped) built with Zig and linking a few LLVM libraries has the following sections, most of which have to do with glibc and dynamic linking\cite{nativity}:
	\begin{verbatim}
0 .interp
1 .note.ABI-tag
2 .dynsym
3 .gnu.version 
4 .gnu.version_r
5 .gnu.hash
6 .hash
7 .dynstr
8 .rela.dyn
9 .rela.plt
10 .rodata
11 .eh_frame_hdr
12 .eh_frame
13 .text
14 .init
15 .fini
16 .plt
17 .tbss
18 .init_array
19 .data.rel.ro 
20 .dynamic
21 .got
22 .got.plt
23 .relro_paddin
24 .data
25 .bss
26 .comment
27 .gnu_debuglin
28 .debug_loc
29 .debug_abbrev
30 .debug_info
31 .debug_ranges
32 .debug_str
33 .debug_line
34 .debug_pubnames
35 .debug_pubtypes
36 .debug_frame		
	\end{verbatim}
	
	\paragraph{}At the same time, the specification says that program headers have exclusive utility for shared objects and executables, leaving out relocatable files.
	\paragraph{}Program headers are similar to section headers, only that they tend to group section data into categories according to whether the section must be loaded by the ELF dynamic linker or loader and similar criteria. For instance, there is \verb|PT_LOAD| that informs that the object segment must be loaded into memory, \verb|PT_DYNAMIC| collects dynamic linking information and \verb|PT_INTERP| is used as the path to an interpreter, to mention a few.
	
	\subsubsection{A sea of relocations}
	\paragraph{}Relocations as such are described in a very generic way, which two (\verb|Elf64_Rel|) or three (\verb|Elf64_Rela|) generic fields. The relocation type is encoded as part of the \verb|r_info| field and is architecture-dependent.
	\paragraph{}Since this work only deals with the x86\_64 CPU architecture, such part of the specification will be examined.
	\paragraph{}Nevertheless, the original ELF specification, despite including information for Intel architectures, is previous to the creation of x86\_64, so another document must reached in order to retrieve some certain data about the relocation types for the flagship architecture of Intel and AMD.
	\paragraph{}However, the existence of the relocation data in the original document can help the interested reader understand the growing complexity of linking technology. By the time the ELF specification was published, there were only three possible encodings for relocation types, two of which were actually relocations (where one exists with respect to the program counter).
	
	\paragraph{}The picture is indeed quite different when looking through the document which properly describes the relocation types for the newer x86 extension for, the AMD64 or x86\_64 System V ABI specification\cite{x86_64-abi-spec}. If there were only three options for relocation type in x86, for AMD64 there is a total amount of 38 possible values to encode. This, aside from the increasing complexity of types, has to do with the addition of different sizes, not only the 64-bit one but also 8-bit and 16-bit relocations. By paraphrasing Cliff Click's great work on compilers\cite{sea-of-nodes} in a pejorative sense, it can be concluded that there is a "sea of relocations" in x86\_64.
	
	\subsubsection{Dynamic linking and lazy bindings or sticking code together with too much glue}
	
	\paragraph{}The ploriferation of relocations was accompanied by an increasing complexity in the relationship between different pieces of the code that ought to be linked. The appearance of intermediate linking tables such as the GOT and the PLT introduced unnecessary intermediate steps to a dynamic linking stage already hurt in performance.
	
	\paragraph{}Part of the complexity and overhead introduced by dynamic linking is introduced by lazy bindings\cite{lazy-bindings}. When these are used, the function call to a dynamically-linked symbol jumps into a stub in the PLT section. This PLT stub then jumps into yet another stub, this time in a GOT entry, responsible for loading the symbol on demand using the \verb|dlsym| function from libc. Once the symbol is loaded, GOT entry is updated with the symbol address.
	\paragraph{}This approach ensures that only the symbols that are actually used are loaded, avoiding huge work if large libraries are linked. Nevertheless, the penalty for each symbol load is worse, since the linking of the library cannot be batched.
	\paragraph{}The performance penalty of calling a dynamically-loaded function can be summed up by a couple of jumps (from the calling code to the PLT and from the PLT to the actual function) and an extra memory dereference (the function address contained in the GOT entry), provided that the function is not called for the first time. This could signify the presence of a few unnecessary cache misses as opposed to the simple \verb|call| with a RIP-relative operand.
	\paragraph{}This triple indirection poses an obvious penalty and thus dynamic linking with lazy bindings features meaningful overhead in both speed and size.
	
	\subsection{Simplification of executable formats}
	\subsubsection{Executables and libraries}
	
	\paragraph{Does this belong here?} This will be achieved by adding some entry points to the binary in case the binary is being executed from a shell so that the user is able to interact properly with the functionality of the code hosted by the binary.
	
	\paragraph{TODO: place this somewhere else:}However, the preferred way to link programs and scale is through using the binary and linking library functions into an executable, not calling out shell programs.
	
	\paragraph{TODO. Move this paragraph below? Detail better}It can be thought that this binary format supports a few use cases that were listed on the goals of this thesis, but in practice the diversification makes them to be far from close to each other. This is even more palpable when exemplified with existing libraries such the GNU libc. More detail on this will be given below.
	
	\subsubsection{Dynamic and static libraries}
	
	\paragraph{}TODO
	
	\subsubsection{Relocation types}
	
	\paragraph{}I have been doing some research on how to make consistent the relocation types between static and dynamic libraries and to me it feels like these are massively overcomplicated and that only using instruction pointer relative addressing (RIP-relative addressing in x86\_64) could work very well for both of them. This makes everything so much more simple, at the cost of not depending on any library which uses GOT, PLT or something similar, like GNU libc. For the same reason, this relative addressing has been chosen to have just 32-bit operands, so that no different types of relocations exist at all and pave the way for an implementation given the time constraint.
	
	\subsection{Loader implementation}
	
	\paragraph{}This is possible in Linux and any modern operating system by using system calls like \verb|mmap| which allow the user to mark some allocated virtual memory region as executable. This program will serve as a way to verify the executable is correctly formed and to load the executable in memory without modifying any kernel source code.
	
	\subsection{Linker implementation}
	
	\paragraph{} TODO
	
	\subsection{Machine code generation}
	
	\paragraph{}This is due to the malleability that such method provides, giving me full control over the bytes generated, avoiding undesired byte output and making me easier to emit relocations in the middle of such code. While this ensures more control, the ability to have a more worthwhile code to show along the loader/linker program is lost, which I certainly believe is a fine trade-off to make since the interesting bit of this work is the linking and loading technology, not the code which is to be linked or loaded.
	
	\section{Results}
	\paragraph{}TODO
	
	\section{Conclusion and Future Work}
	\paragraph{}TODO
	
	\section{Glossary}
	\paragraph{}TODO

	\begin{thebibliography}{9}
		\bibitem{self} \href{https://github.com/davidgm94/modern-machine-code-format/}{https://github.com/davidgm94/modern-machine-code-format/}\\
		Retrieved 28 May 2024.
		\bibitem{thirty-million}
		\href{https://www.youtube.com/watch?v=kZRE7HIO3vk}{https://www.youtube.com/watch?v=kZRE7HIO3vk}\\
		Retrieved 01 June 2024.
		\bibitem{lemire-energy}
		\href{https://lemire.me/blog/2024/02/19/measuring-energy-usage-regular-code-vs-simd-code}{https://lemire.me/blog/2024/02/19/measuring-energy-usage-regular-code-vs-simd-code/}\\
		Retrieved 28 May 2024.
		\bibitem{elf-spec}
		\href{https://refspecs.linuxfoundation.org/elf/elf.pdf}{https://refspecs.linuxfoundation.org/elf/elf.pdf}\\
		Retrieved 29 May 2024.
		\bibitem{nativity}
		\href{https://github.com/birth-software/nativity}{https://github.com/birth-software/nativity}\\
		Retrieved 1 June 2024.
		\bibitem{x86_64-abi-spec}
		\href{https://refspecs.linuxbase.org/elf/x86_64-abi-0.99.pdf}{https://refspecs.linuxbase.org/elf/x86\_64-abi-0.99.pdf}\\
		Retrieved 29 May 2024.
		\bibitem{sea-of-nodes}
		\href{https://www.youtube.com/watch?v=98lt45Aj8mo}{https://www.youtube.com/watch?v=98lt45Aj8mo}\\
		Retrieved 30 May 2024.
		\bibitem{lazy-bindings}
		\href{https://www.qnx.com/developers/docs/8.0/com.qnx.doc.neutrino.prog/topic/devel_Lazy_binding.html}{https://www.qnx.com/developers/docs/8.0/com.qnx.doc.neutrino.prog/topic/devel\_Lazy\_binding.html}\\
		Retrieved 30 May 2024.
	\end{thebibliography}

	% Extra sources:
	%How programs get run
	%https://lwn.net/Articles/630727/
	%How programs get run: ELF binaries
	%https://lwn.net/Articles/631631/
	%GCC codegen options
	%https://gcc.gnu.org/onlinedocs/gcc/Code-Gen-Options.html
	% Computer Science from the Bottom Up. Chapter 9. Dynamic linking
	%https://bottomupcs.sourceforge.net/csbu/c3673.htm
	%All about Global Offset Table
	%https://maskray.me/blog/2021-08-29-all-about-global-offset-table
\end{document}
